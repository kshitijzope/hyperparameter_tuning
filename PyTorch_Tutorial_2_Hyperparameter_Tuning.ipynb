{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Da5dPCYHSNc8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHCJKdTTSW2",
        "outputId": "b6c7acde-cc6b-453b-877f-496319699897"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b0YgBs-rTVdl",
        "outputId": "61d7051c-eee3-4145-f43a-780140a4af90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esvXXaLpTaWs",
        "outputId": "7ea9659d-4c1b-490d-8360-f03a71d86199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12880929.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 196803.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:06<00:00, 671275.18it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4303822.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser/pants','Pullover shirt','Dress','Coat','Sandal',\n",
        "           'Shirt','Sneaker','Bag','Ankle boot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv61q2CRTscr",
        "outputId": "65aacc09-1b10-49d3-9e2c-00a10ae4ec7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_iter = iter(trainset)\n",
        "\n",
        "image, label = next(train_iter)\n",
        "\n",
        "image.shape, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl69nSx9T31c",
        "outputId": "c20ac76f-4b88-4aa0-d22a-73d40b23cee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.min(image).item(), torch.max(image).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "7qvTgLAUUFjk",
        "outputId": "d528f515-b60b-4037-f6b5-d8a143ecadfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle boot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2142f71ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np_img = image.numpy()\n",
        "print(classes[label])\n",
        "plt.imshow(np_img.reshape((28, 28, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQXC6gXJUmPL",
        "outputId": "30d93c2d-acd4-4aa7-baad-231a93b7874f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(trainset), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKEJe7irU2l7",
        "outputId": "50de3320-f691-457a-a576-4410129fba12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainset, valset = torch.utils.data.random_split(trainset, [50000, 10000])\n",
        "len(trainset), len(valset), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11GjhMnnVitC",
        "outputId": "0246008e-e4a3-4f41-deb9-90a4c9beff54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in the training set: 12500\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of batches in the training set: {int(50000 / batch_size)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpGNlyNpVql0",
        "outputId": "66a8df76-2f76-47ec-9e9c-0475e0a012e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in the validation set: 2500\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of batches in the validation set: {int(10000 / batch_size)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "1DptfI2GVxB7",
        "outputId": "a7582ebe-d0ca-4e6e-ee2b-8abc1fc2a778"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataset.Subset</b><br/>def __init__(dataset: Dataset[T_co], indices: Sequence[int]) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py</a>Subset of a dataset at specified indices.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): The whole Dataset\n",
              "    indices (sequence): Indices in the whole set selected for subset</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 393);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "type(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i3l_s-ebV-lB"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vqKVh9gVWMUJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(256)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(512)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.avg_pool = nn.AvgPool2d(5, 5)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=512, out_features=512)\n",
        "        self.drop1 = nn.Dropout(p=0.1)\n",
        "\n",
        "        self.out = nn.Linear(in_features=512, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        #print(f'Shape before pool: {x.shape}')\n",
        "        x = self.avg_pool(x)\n",
        "        #print(f'Shape after pool: {x.shape}')\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC6lWyCpZCy9",
        "outputId": "bd384577-88fe-461f-d271-e7013134a3b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (avg_pool): AvgPool2d(kernel_size=5, stride=5, padding=0)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (drop1): Dropout(p=0.1, inplace=False)\n",
              "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "net = NeuralNet()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iULK0aXEZQ9P",
        "outputId": "7d16afbc-1e45-407b-aa54-bfcb0147ffef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([4, 1, 28, 28])\n",
            "after network shape: torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    print(f'input shape: {inputs.shape}')\n",
        "    print(f'after network shape: {net(inputs).shape}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8H3OZApZoSO",
        "outputId": "65f326c9-6cf1-4684-eaca-d2bd72087a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters in the model: 1,452,042\n"
          ]
        }
      ],
      "source": [
        "num_params = 0\n",
        "for x in net.parameters():\n",
        "  num_params += len(torch.flatten(x))\n",
        "\n",
        "print(f'Number of parameters in the model: {num_params:,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MhrPoDPBgybm"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XLFPG1sjmOdI"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch():\n",
        "  net.train(True)\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "\n",
        "  for batch_index, data in enumerate(trainloader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(inputs) # shape: [batch_size, 10]\n",
        "    correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "    running_accuracy += correct / batch_size\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_index % 500 == 499:  # print every 500 batches\n",
        "      avg_loss_across_batches = running_loss / 500\n",
        "      avg_acc_across_batches = (running_accuracy / 500) * 100\n",
        "      print('Batch {0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1,\n",
        "                                                          avg_loss_across_batches,\n",
        "                                                          avg_acc_across_batches))\n",
        "      running_loss = 0.0\n",
        "      running_accuracy = 0.0\n",
        "\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LvR78xwmsGh_"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch():\n",
        "    net.train(False)\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for i, data in enumerate(valloader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs) # shape: [batch_size, 10]\n",
        "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "            running_accuracy += correct / batch_size\n",
        "            loss = criterion(outputs, labels) # One number, the average batch loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    avg_loss_across_batches = running_loss / len(valloader)\n",
        "    avg_acc_across_batches = (running_accuracy / len(valloader)) * 100\n",
        "\n",
        "    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches,\n",
        "                                                            avg_acc_across_batches))\n",
        "    print('***************************************************')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmeXH9yXjx_y",
        "outputId": "9e3fe09a-cd22-485b-e244-9d3353eaabb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Batch 500, Loss: 1.137, Accuracy: 59.9%\n",
            "Batch 1000, Loss: 0.771, Accuracy: 71.0%\n",
            "Batch 1500, Loss: 0.657, Accuracy: 74.7%\n",
            "Batch 2000, Loss: 0.673, Accuracy: 75.6%\n",
            "Batch 2500, Loss: 0.604, Accuracy: 78.0%\n",
            "Batch 3000, Loss: 0.572, Accuracy: 78.1%\n",
            "Batch 3500, Loss: 0.563, Accuracy: 79.7%\n",
            "Batch 4000, Loss: 0.562, Accuracy: 78.6%\n",
            "Batch 4500, Loss: 0.518, Accuracy: 81.2%\n",
            "Batch 5000, Loss: 0.533, Accuracy: 79.2%\n",
            "Batch 5500, Loss: 0.502, Accuracy: 81.9%\n",
            "Batch 6000, Loss: 0.473, Accuracy: 81.7%\n",
            "Batch 6500, Loss: 0.489, Accuracy: 82.0%\n",
            "Batch 7000, Loss: 0.488, Accuracy: 83.3%\n",
            "Batch 7500, Loss: 0.527, Accuracy: 81.0%\n",
            "Batch 8000, Loss: 0.465, Accuracy: 83.0%\n",
            "Batch 8500, Loss: 0.470, Accuracy: 82.9%\n",
            "Batch 9000, Loss: 0.453, Accuracy: 83.4%\n",
            "Batch 9500, Loss: 0.464, Accuracy: 82.7%\n",
            "Batch 10000, Loss: 0.476, Accuracy: 82.2%\n",
            "Batch 10500, Loss: 0.450, Accuracy: 83.2%\n",
            "Batch 11000, Loss: 0.458, Accuracy: 82.8%\n",
            "Batch 11500, Loss: 0.451, Accuracy: 83.9%\n",
            "Batch 12000, Loss: 0.439, Accuracy: 84.2%\n",
            "Batch 12500, Loss: 0.442, Accuracy: 83.5%\n",
            "\n",
            "Val Loss: 0.452, Val Accuracy: 84.6%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Batch 500, Loss: 0.413, Accuracy: 85.4%\n",
            "Batch 1000, Loss: 0.382, Accuracy: 86.2%\n",
            "Batch 1500, Loss: 0.405, Accuracy: 84.5%\n",
            "Batch 2000, Loss: 0.415, Accuracy: 85.0%\n",
            "Batch 2500, Loss: 0.421, Accuracy: 85.4%\n",
            "Batch 3000, Loss: 0.440, Accuracy: 84.6%\n",
            "Batch 3500, Loss: 0.405, Accuracy: 85.2%\n",
            "Batch 4000, Loss: 0.394, Accuracy: 85.0%\n",
            "Batch 4500, Loss: 0.406, Accuracy: 85.5%\n",
            "Batch 5000, Loss: 0.437, Accuracy: 84.5%\n",
            "Batch 5500, Loss: 0.421, Accuracy: 84.5%\n",
            "Batch 6000, Loss: 0.388, Accuracy: 86.2%\n",
            "Batch 6500, Loss: 0.347, Accuracy: 86.6%\n",
            "Batch 7000, Loss: 0.406, Accuracy: 84.9%\n",
            "Batch 7500, Loss: 0.383, Accuracy: 85.6%\n",
            "Batch 8000, Loss: 0.414, Accuracy: 84.9%\n",
            "Batch 8500, Loss: 0.402, Accuracy: 85.5%\n",
            "Batch 9000, Loss: 0.371, Accuracy: 86.7%\n",
            "Batch 9500, Loss: 0.370, Accuracy: 86.2%\n",
            "Batch 10000, Loss: 0.398, Accuracy: 84.9%\n",
            "Batch 10500, Loss: 0.346, Accuracy: 86.9%\n",
            "Batch 11000, Loss: 0.422, Accuracy: 84.2%\n",
            "Batch 11500, Loss: 0.385, Accuracy: 85.2%\n",
            "Batch 12000, Loss: 0.375, Accuracy: 86.2%\n",
            "Batch 12500, Loss: 0.388, Accuracy: 86.4%\n",
            "\n",
            "Val Loss: 1.053, Val Accuracy: 85.1%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Batch 500, Loss: 0.371, Accuracy: 86.8%\n",
            "Batch 1000, Loss: 0.342, Accuracy: 86.8%\n",
            "Batch 1500, Loss: 0.357, Accuracy: 86.6%\n",
            "Batch 2000, Loss: 0.365, Accuracy: 86.9%\n",
            "Batch 2500, Loss: 0.351, Accuracy: 87.5%\n",
            "Batch 3000, Loss: 0.346, Accuracy: 87.0%\n",
            "Batch 3500, Loss: 0.394, Accuracy: 85.5%\n",
            "Batch 4000, Loss: 0.359, Accuracy: 87.8%\n",
            "Batch 4500, Loss: 0.364, Accuracy: 87.0%\n",
            "Batch 5000, Loss: 0.314, Accuracy: 87.9%\n",
            "Batch 5500, Loss: 0.367, Accuracy: 86.8%\n",
            "Batch 6000, Loss: 0.341, Accuracy: 87.2%\n",
            "Batch 6500, Loss: 0.361, Accuracy: 87.0%\n",
            "Batch 7000, Loss: 0.391, Accuracy: 86.2%\n",
            "Batch 7500, Loss: 0.353, Accuracy: 86.1%\n",
            "Batch 8000, Loss: 0.385, Accuracy: 85.4%\n",
            "Batch 8500, Loss: 0.370, Accuracy: 87.4%\n",
            "Batch 9000, Loss: 0.369, Accuracy: 86.4%\n",
            "Batch 9500, Loss: 0.344, Accuracy: 87.5%\n",
            "Batch 10000, Loss: 0.361, Accuracy: 85.8%\n",
            "Batch 10500, Loss: 0.360, Accuracy: 87.6%\n",
            "Batch 11000, Loss: 0.340, Accuracy: 87.8%\n",
            "Batch 11500, Loss: 0.375, Accuracy: 85.1%\n",
            "Batch 12000, Loss: 0.328, Accuracy: 87.9%\n",
            "Batch 12500, Loss: 0.333, Accuracy: 87.7%\n",
            "\n",
            "Val Loss: 1.194, Val Accuracy: 86.8%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Batch 500, Loss: 0.338, Accuracy: 86.9%\n",
            "Batch 1000, Loss: 0.333, Accuracy: 87.0%\n",
            "Batch 1500, Loss: 0.323, Accuracy: 88.0%\n",
            "Batch 2000, Loss: 0.325, Accuracy: 87.9%\n",
            "Batch 2500, Loss: 0.331, Accuracy: 86.9%\n",
            "Batch 3000, Loss: 0.348, Accuracy: 86.9%\n",
            "Batch 3500, Loss: 0.316, Accuracy: 88.5%\n",
            "Batch 4000, Loss: 0.360, Accuracy: 86.6%\n",
            "Batch 4500, Loss: 0.321, Accuracy: 88.6%\n",
            "Batch 5000, Loss: 0.309, Accuracy: 88.8%\n",
            "Batch 5500, Loss: 0.320, Accuracy: 87.9%\n",
            "Batch 6000, Loss: 0.329, Accuracy: 87.4%\n",
            "Batch 6500, Loss: 0.335, Accuracy: 87.7%\n",
            "Batch 7000, Loss: 0.325, Accuracy: 87.7%\n",
            "Batch 7500, Loss: 0.293, Accuracy: 89.1%\n",
            "Batch 8000, Loss: 0.311, Accuracy: 87.8%\n",
            "Batch 8500, Loss: 0.357, Accuracy: 86.5%\n",
            "Batch 9000, Loss: 0.360, Accuracy: 86.8%\n",
            "Batch 9500, Loss: 0.328, Accuracy: 88.2%\n",
            "Batch 10000, Loss: 0.318, Accuracy: 88.9%\n",
            "Batch 10500, Loss: 0.348, Accuracy: 87.5%\n",
            "Batch 11000, Loss: 0.340, Accuracy: 88.1%\n",
            "Batch 11500, Loss: 0.308, Accuracy: 87.9%\n",
            "Batch 12000, Loss: 0.349, Accuracy: 86.8%\n",
            "Batch 12500, Loss: 0.312, Accuracy: 88.4%\n",
            "\n",
            "Val Loss: 2.374, Val Accuracy: 86.0%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Batch 500, Loss: 0.285, Accuracy: 89.8%\n",
            "Batch 1000, Loss: 0.293, Accuracy: 89.1%\n",
            "Batch 1500, Loss: 0.292, Accuracy: 88.8%\n",
            "Batch 2000, Loss: 0.325, Accuracy: 88.2%\n",
            "Batch 2500, Loss: 0.305, Accuracy: 89.6%\n",
            "Batch 3000, Loss: 0.302, Accuracy: 88.6%\n",
            "Batch 3500, Loss: 0.328, Accuracy: 87.4%\n",
            "Batch 4000, Loss: 0.327, Accuracy: 88.4%\n",
            "Batch 4500, Loss: 0.291, Accuracy: 89.3%\n",
            "Batch 5000, Loss: 0.311, Accuracy: 87.8%\n",
            "Batch 5500, Loss: 0.308, Accuracy: 88.6%\n",
            "Batch 6000, Loss: 0.325, Accuracy: 88.1%\n",
            "Batch 6500, Loss: 0.296, Accuracy: 89.2%\n",
            "Batch 7000, Loss: 0.322, Accuracy: 88.2%\n",
            "Batch 7500, Loss: 0.317, Accuracy: 87.2%\n",
            "Batch 8000, Loss: 0.326, Accuracy: 87.1%\n",
            "Batch 8500, Loss: 0.312, Accuracy: 89.4%\n",
            "Batch 9000, Loss: 0.303, Accuracy: 88.3%\n",
            "Batch 9500, Loss: 0.309, Accuracy: 88.2%\n",
            "Batch 10000, Loss: 0.303, Accuracy: 88.6%\n",
            "Batch 10500, Loss: 0.314, Accuracy: 88.5%\n",
            "Batch 11000, Loss: 0.303, Accuracy: 88.6%\n",
            "Batch 11500, Loss: 0.298, Accuracy: 89.7%\n",
            "Batch 12000, Loss: 0.357, Accuracy: 87.5%\n",
            "Batch 12500, Loss: 0.308, Accuracy: 88.3%\n",
            "\n",
            "Val Loss: 0.909, Val Accuracy: 88.5%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Batch 500, Loss: 0.287, Accuracy: 89.5%\n",
            "Batch 1000, Loss: 0.266, Accuracy: 90.0%\n",
            "Batch 1500, Loss: 0.282, Accuracy: 89.1%\n",
            "Batch 2000, Loss: 0.273, Accuracy: 89.8%\n",
            "Batch 2500, Loss: 0.315, Accuracy: 87.9%\n",
            "Batch 3000, Loss: 0.286, Accuracy: 89.5%\n",
            "Batch 3500, Loss: 0.316, Accuracy: 88.6%\n",
            "Batch 4000, Loss: 0.278, Accuracy: 89.2%\n",
            "Batch 4500, Loss: 0.295, Accuracy: 89.2%\n",
            "Batch 5000, Loss: 0.276, Accuracy: 90.0%\n",
            "Batch 5500, Loss: 0.312, Accuracy: 88.3%\n",
            "Batch 6000, Loss: 0.293, Accuracy: 88.8%\n",
            "Batch 6500, Loss: 0.293, Accuracy: 89.5%\n",
            "Batch 7000, Loss: 0.283, Accuracy: 88.9%\n",
            "Batch 7500, Loss: 0.304, Accuracy: 88.8%\n",
            "Batch 8000, Loss: 0.291, Accuracy: 89.3%\n",
            "Batch 8500, Loss: 0.304, Accuracy: 88.8%\n",
            "Batch 9000, Loss: 0.314, Accuracy: 88.2%\n",
            "Batch 9500, Loss: 0.311, Accuracy: 88.6%\n",
            "Batch 10000, Loss: 0.324, Accuracy: 89.0%\n",
            "Batch 10500, Loss: 0.313, Accuracy: 88.0%\n",
            "Batch 11000, Loss: 0.327, Accuracy: 87.6%\n",
            "Batch 11500, Loss: 0.258, Accuracy: 89.9%\n",
            "Batch 12000, Loss: 0.303, Accuracy: 89.3%\n",
            "Batch 12500, Loss: 0.279, Accuracy: 89.6%\n",
            "\n",
            "Val Loss: 2.427, Val Accuracy: 87.1%\n",
            "***************************************************\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Batch 500, Loss: 0.265, Accuracy: 90.0%\n",
            "Batch 1000, Loss: 0.289, Accuracy: 89.3%\n",
            "Batch 1500, Loss: 0.246, Accuracy: 91.4%\n",
            "Batch 2000, Loss: 0.288, Accuracy: 89.5%\n",
            "Batch 2500, Loss: 0.257, Accuracy: 90.8%\n",
            "Batch 3000, Loss: 0.243, Accuracy: 90.4%\n",
            "Batch 3500, Loss: 0.296, Accuracy: 89.4%\n",
            "Batch 4000, Loss: 0.294, Accuracy: 88.9%\n",
            "Batch 4500, Loss: 0.263, Accuracy: 90.8%\n",
            "Batch 5000, Loss: 0.279, Accuracy: 89.3%\n",
            "Batch 5500, Loss: 0.307, Accuracy: 88.8%\n",
            "Batch 6000, Loss: 0.269, Accuracy: 90.0%\n",
            "Batch 6500, Loss: 0.270, Accuracy: 90.6%\n",
            "Batch 7000, Loss: 0.286, Accuracy: 89.8%\n",
            "Batch 7500, Loss: 0.301, Accuracy: 88.4%\n",
            "Batch 8000, Loss: 0.295, Accuracy: 89.4%\n",
            "Batch 8500, Loss: 0.291, Accuracy: 89.5%\n",
            "Batch 9000, Loss: 0.287, Accuracy: 88.9%\n",
            "Batch 9500, Loss: 0.285, Accuracy: 89.1%\n",
            "Batch 10000, Loss: 0.294, Accuracy: 88.9%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch_index in range(num_epochs):\n",
        "    print(f'Epoch: {epoch_index + 1}\\n')\n",
        "\n",
        "    train_one_epoch()\n",
        "    validate_one_epoch()\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ95sBWotl-V"
      },
      "outputs": [],
      "source": [
        "# val accuracy 87.9%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:pytorch_gpu]",
      "language": "python",
      "name": "conda-env-pytorch_gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}